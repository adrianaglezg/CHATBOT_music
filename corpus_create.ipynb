{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk \n",
    "import numpy as np\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_feature_database = 'data/all_extracted_features.json'\n",
    "with open(path_feature_database, \"r\", encoding=\"utf-8\") as file:\n",
    "    corpus_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(r'C:\\Users\\34640\\Desktop\\VSCode\\z_Cursos_Python\\chatbots\\data\\all_extracted_features.txt', 'r', errors= 'ignore')\n",
    "# raw = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"mood_1\": \"Weightlessness\",\n",
      "        \"text_1\": \"Input (Mood: Anxious, restless):\\n\\nI can't seem to sit still, my mind racing with \\\"what ifs\\\" and worst-case scenarios.  A low, throbbing bassline would capture that feeling of unease perfectly, maybe with high-pitched strings weaving in and out, mirroring the chaotic thoughts.  It needs to be fast, frantic even, but with a driving rhythm to keep the anxiety from overwhelming everything.  I need something to ground me, but something that acknowledges this feeling.\\n\",\n",
      "        \"features_1\": \"```json\\n{\\n  \\\"Tempo\\\": \\\"140 bpm\\\",\\n  \\\"Intensity/Dynamics\\\": \\\"mf - crescendo to ff during the \\\"what ifs\\\" section, then diminuendo to mp\\\",\\n  \\\"Timbre\\\": \\\"Dark, with a focus on low \n"
     ]
    }
   ],
   "source": [
    "# print(raw[:750])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuring that our raw corpus retains '\\n' and similar markers is crucial, allowing our future chatbot to correctly segment sentences and paragraphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepropecing the corpus\n",
    "\n",
    "This stage will involve several NLP techniques, including tokenization, stop word removal, lemmatization, and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet') \n",
    "# make sur to have this libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracts the preprocessed texts from the corpus to maintain the reference to their features\n",
    "corpus_texts = []\n",
    "corpus_features = []  \n",
    "\n",
    "for entry in corpus_data:\n",
    "    for key in entry:\n",
    "        if key.startswith(\"text_\"):  \n",
    "            corpus_texts.append(entry[key]) \n",
    "\n",
    "for entry in corpus_data:\n",
    "    for key in entry:\n",
    "        if key.startswith(\"features_\"):  \n",
    "            corpus_features.append(entry[key])\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We subdivide the raw corpus to facilitate later vectorization of both the users' texts in the corpus and the new input from the person interacting with the bot. This allows us to identify the most similar text using cosine distance and retrieve its corresponding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Overwhelmed.  A cacophony of noise in my head, a frantic rhythm that won't slow down.  I need music to match â€“ something chaotic but ultimately resolving, maybe a crescendo into a quiet, peaceful ending.  Please, something to calm this storm.\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_texts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"Tempo\": \"Allegro molto (very fast) initially, gradually slowing to Adagio (slow)\",\\n  \"Intensity/Dynamics\": \"Fortissimo (very loud) crescendo to pianissimo (very soft)\",\\n  \"Timbre\": \"Initially brassy and harsh, gradually softening to strings and woodwinds with a mellow tone\",\\n  \"Rhythm\": \"Initially irregular and complex polyrhythms, gradually resolving into a simple, regular beat\",\\n  \"Harmonic progression\": \"Cm - Bâ™­ - Aâ™­ - Gâ™­ - F - Eb - Dâ™­ - C (Descending chromatic scale resolving to tonic)\",\\n  \"Melody\": \"Initially erratic and disjointed leaps, gradually becoming smoother and descending towards the end\",\\n  \"Tonality/Mode\": \"C minor, moving towards C major at the end\",\\n  \"Articulation\": \"Initially staccato and aggressive, gradually becoming legato and flowing\",\\n  \"Silence\": \"Long pause at the very end\"\\n}\\n```\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_features[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    ''' \n",
    "    tokenizes, removes punctuation and lemmatizes\n",
    "    '''\n",
    "    tokens = nltk.word_tokenize(text.lower().translate(remove_punct_dict))\n",
    "    return \" \".join(lemmatizer.lemmatize(token) for token in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_response(user_input, features= corpus_features):\n",
    "    ''' \n",
    "    response based on cosine similarity\n",
    "    '''   \n",
    "\n",
    "    processed_input = preprocess_text(user_input)\n",
    "\n",
    "    user_vector = vectorizer.transform([processed_input])\n",
    "\n",
    "    similarities = cosine_similarity(user_vector, tfidf_matrix)\n",
    "\n",
    "    # find best index to return the features\n",
    "    best_match_idx = np.argmax(similarities)\n",
    "    best_match_features = features[best_match_idx]\n",
    "\n",
    "    return best_match_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in c:\\users\\34640\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.9)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: six in c:\\users\\34640\\appdata\\roaming\\python\\python312\\site-packages (from langdetect) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langdetect \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "import threading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeout = 10  # Tiempo lÃ­mite en segundos\n",
    "# stop_event = threading.Event()  # Evento para controlar el tiempo de espera\n",
    "\n",
    "# def countdown_timer():\n",
    "#     \"\"\"FunciÃ³n que espera el tiempo lÃ­mite y termina el programa si no hay input.\"\"\"\n",
    "#     global stop_event\n",
    "#     while not stop_event.wait(timeout):\n",
    "#         print(\"\\nğŸ•‘ Timeout reached! No input received. Exiting...\")\n",
    "#         exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‘¤ğŸ’¬ ytavsgbhkjfshdg \n",
      "\n",
      "ğŸ¤–âŒ Sorry, I can't understand your text. It must be written in English.\n",
      "\n",
      "ğŸ‘¤ğŸ’¬ hola caracola  \n",
      "\n",
      "ğŸ¤–âŒ Sorry, I can't understand your text. It must be written in English.\n",
      "\n",
      "ğŸ‘¤ğŸ’¬ im feeling ver sad today, i want something in A minor \n",
      "\n",
      "ğŸ¤– We are processing your feelings to return the best musical match for you... â³\n",
      "\n",
      "ğŸ¤– here it is!. \n",
      "This are the features that have been considered the most accurate for your text:\n",
      "\n",
      "\"```json\n",
      "{\n",
      "  \"Tempo\": \"Allegro molto (very fast, around 160 bpm)\",\n",
      "  \"Intensity/Dynamics\": \"mf (moderately loud) to ff (very loud) with sudden diminuendos to p (soft) creating a sense of unease and tension.\",\n",
      "  \"Timbre\": \"Bright, almost metallic timbre achieved through the use of high-register strings and brass with a slightly distorted or edgy quality.\",\n",
      "  \"Rhythm\": \"Irregular, syncopated rhythms with sudden changes in meter to reflect the chaotic and unpredictable nature of anxiety.\",\n",
      "  \"Harmonic progression\": \"A minor-D minor-E7-A minor (i-iv-V7-i) with frequent use of chromatic passing chords and augmented chords to intensify the dissonant feeling.\",\n",
      "  \"Melody\": \"Fragmentary and restless melodies that jump around erratically between high and low registers, often unresolved, reflecting the racing mind.\",\n",
      "  \"Tonality/Mode\": \"A minor (natural minor)\",\n",
      "  \"Articulation\": \"Staccato and marcato (stressed) articulation in the melodic lines to reflect the nervous energy.  Some legato passages in lower register instruments to create moments of impending dread.\",\n",
      "  \"Silence\": \"Minimal use of silence, with sudden breaks used sparingly to heighten the tension before resuming the frenetic pace.\"\n",
      "}\n",
      "```\n",
      "\"\n",
      "hope it helped :)\n",
      "\n",
      "ğŸ‘¤ğŸ’¬ tha NK Y Ou \n",
      "\n",
      "ğŸ¤– You'r wellcome\n"
     ]
    }
   ],
   "source": [
    "# timer_thread = threading.Thread(target=countdown_timer, daemon=True)\n",
    "# timer_thread.start()\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\\nğŸ‘¤ Share how you're feeling or what's on your mind (or type 'exit' to close this session): \")\n",
    "\n",
    "    # stop_event.set()\n",
    "    # stop_event.clear() #restart\n",
    "\n",
    "    print(f\"\\nğŸ‘¤ğŸ’¬ {user_input} \")\n",
    "\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"\\nğŸ‘‹ğŸ¤– good bye!\")\n",
    "        break\n",
    "\n",
    "    elif user_input.lower().replace(\" \", \"\") == \"thankyou\":\n",
    "        print(\"\\nğŸ¤– You'r wellcome\")\n",
    "        break\n",
    "        \n",
    "    elif user_input.replace(\" \", \"\") == \"\":\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        \n",
    "\n",
    "        language = detect(user_input)  \n",
    "        if language != \"en\":\n",
    "            print(\"\\nğŸ¤–âŒ Sorry, I can't understand your text. It must be written in English.\")\n",
    "            continue  \n",
    "        \n",
    "        print(\"\\nğŸ¤– We are processing your feelings to return the best musical match for you... â³\")\n",
    "        response = chatbot_response(user_input)\n",
    "        print(\"\\nğŸ¤– here it is!. \\nThis are the features that have been considered the most accurate for your text:\\n\")\n",
    "        # print(json.dumps(response, indent=4, ensure_ascii=False))\n",
    "        print(json.dumps(response, ensure_ascii=False).replace(\"\\\\n\", \"\\n\").replace('\\\\', \"\"))\n",
    "        print('hope it helped :)')\n",
    "        # break\n",
    "\n",
    "\n",
    "            \n",
    "    except:\n",
    "        print(\"\\nğŸ¤–âŒ Sorry, I couldn't detect the language of your text. Please try again.\")\n",
    "\n",
    "    # if stop_event.is_set(): \n",
    "    #         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
